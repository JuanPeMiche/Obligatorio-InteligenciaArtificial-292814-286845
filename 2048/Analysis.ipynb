{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab49504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# ConfiguraciÃ³n de visualizaciÃ³n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Crear directorio para plots si no existe\n",
    "Path(\"results/plots\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cfbd4b",
   "metadata": {},
   "source": [
    "## 1. Cargar Resultados\n",
    "\n",
    "Carga todos los archivos CSV de resultados generados por los experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec048c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_results(results_dir=\"results\"):\n",
    "    \"\"\"Carga todos los archivos CSV de resultados\"\"\"\n",
    "    csv_files = glob.glob(f\"{results_dir}/*.csv\")\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(\"âš ï¸ No se encontraron archivos de resultados.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"ðŸ“ Archivos encontrados: {len(csv_files)}\")\n",
    "    for f in csv_files:\n",
    "        print(f\"  - {Path(f).name}\")\n",
    "    \n",
    "    # Cargar y combinar todos los DataFrames\n",
    "    dfs = []\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "        df['source_file'] = Path(file).stem\n",
    "        dfs.append(df)\n",
    "    \n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"\\nâœ“ Total de partidas cargadas: {len(combined_df)}\")\n",
    "    print(f\"âœ“ Agentes Ãºnicos: {combined_df['agent_name'].nunique()}\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Cargar datos\n",
    "df_all = load_all_results()\n",
    "\n",
    "if df_all is not None:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VISTA PREVIA DE LOS DATOS\")\n",
    "    print(\"=\"*60)\n",
    "    display(df_all.head())\n",
    "    print(\"\\nColumnas disponibles:\", list(df_all.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a6cbf6",
   "metadata": {},
   "source": [
    "## 2. EstadÃ­sticas Generales\n",
    "\n",
    "Resumen estadÃ­stico de todos los agentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25011817",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_all is not None:\n",
    "    # Agrupar por agente\n",
    "    stats = df_all.groupby('agent_name').agg({\n",
    "        'max_tile': ['mean', 'std', 'max', 'min'],\n",
    "        'final_score': ['mean', 'std', 'max'],\n",
    "        'moves': ['mean', 'std'],\n",
    "        'time_seconds': ['mean', 'sum'],\n",
    "        'game_id': 'count'  # NÃºmero de partidas\n",
    "    }).round(2)\n",
    "    \n",
    "    stats.columns = ['_'.join(col).strip() for col in stats.columns.values]\n",
    "    stats = stats.rename(columns={'game_id_count': 'num_games'})\n",
    "    stats = stats.sort_values('max_tile_mean', ascending=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ESTADÃSTICAS POR AGENTE\")\n",
    "    print(\"=\"*60)\n",
    "    display(stats)\n",
    "    \n",
    "    # Guardar\n",
    "    stats.to_csv('results/summary_statistics.csv')\n",
    "    print(\"\\nâœ“ EstadÃ­sticas guardadas en: results/summary_statistics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c4243e",
   "metadata": {},
   "source": [
    "## 3. VisualizaciÃ³n: ComparaciÃ³n de Max Tiles\n",
    "\n",
    "GrÃ¡fico de barras comparando el max tile promedio alcanzado por cada agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad210d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_all is not None:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # GrÃ¡fico 1: Max Tile Promedio\n",
    "    agent_stats = df_all.groupby('agent_name')['max_tile'].agg(['mean', 'std']).sort_values('mean', ascending=False)\n",
    "    \n",
    "    ax1.bar(range(len(agent_stats)), agent_stats['mean'], \n",
    "            yerr=agent_stats['std'], capsize=5, alpha=0.7)\n",
    "    ax1.set_xticks(range(len(agent_stats)))\n",
    "    ax1.set_xticklabels(agent_stats.index, rotation=45, ha='right')\n",
    "    ax1.set_ylabel('Max Tile Promedio')\n",
    "    ax1.set_title('ComparaciÃ³n de Max Tile Alcanzado')\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # AÃ±adir lÃ­neas de referencia\n",
    "    for tile in [128, 256, 512, 1024, 2048]:\n",
    "        ax1.axhline(y=tile, color='red', linestyle='--', alpha=0.3, linewidth=0.8)\n",
    "        ax1.text(len(agent_stats)-0.5, tile, f'{tile}', fontsize=8, va='bottom')\n",
    "    \n",
    "    # GrÃ¡fico 2: Score Promedio\n",
    "    score_stats = df_all.groupby('agent_name')['final_score'].mean().sort_values(ascending=False)\n",
    "    \n",
    "    ax2.bar(range(len(score_stats)), score_stats.values, alpha=0.7, color='orange')\n",
    "    ax2.set_xticks(range(len(score_stats)))\n",
    "    ax2.set_xticklabels(score_stats.index, rotation=45, ha='right')\n",
    "    ax2.set_ylabel('Score Final Promedio')\n",
    "    ax2.set_title('ComparaciÃ³n de Score Final')\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/plots/comparison_max_tile_score.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ“ GrÃ¡fico guardado en: results/plots/comparison_max_tile_score.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c95db",
   "metadata": {},
   "source": [
    "## 4. DistribuciÃ³n de Max Tiles\n",
    "\n",
    "AnÃ¡lisis de la distribuciÃ³n de fichas mÃ¡ximas alcanzadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb0675",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_all is not None:\n",
    "    # Seleccionar top agentes para mejor visualizaciÃ³n\n",
    "    top_agents = df_all.groupby('agent_name')['max_tile'].mean().nlargest(10).index\n",
    "    df_top = df_all[df_all['agent_name'].isin(top_agents)]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # Crear matriz de distribuciÃ³n\n",
    "    distribution = pd.crosstab(df_top['agent_name'], df_top['max_tile'], normalize='index') * 100\n",
    "    distribution = distribution.reindex(\n",
    "        df_top.groupby('agent_name')['max_tile'].mean().sort_values(ascending=False).index\n",
    "    )\n",
    "    \n",
    "    # Heatmap\n",
    "    sns.heatmap(distribution, annot=True, fmt='.1f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Porcentaje (%)'}, ax=ax)\n",
    "    ax.set_title('DistribuciÃ³n de Max Tiles Alcanzados (%)', fontsize=14, pad=20)\n",
    "    ax.set_xlabel('Max Tile', fontsize=12)\n",
    "    ax.set_ylabel('Agente', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/plots/max_tile_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ“ GrÃ¡fico guardado en: results/plots/max_tile_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27553fcb",
   "metadata": {},
   "source": [
    "## 5. AnÃ¡lisis de Profundidad\n",
    "\n",
    "Si hay experimentos con diferentes profundidades, analizar el impacto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a734938",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_all is not None and 'depth' in df_all.columns:\n",
    "    # Filtrar agentes con informaciÃ³n de profundidad\n",
    "    df_depth = df_all[df_all['depth'].notna()].copy()\n",
    "    \n",
    "    if len(df_depth) > 0:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # 1. Max Tile vs Depth\n",
    "        depth_stats = df_depth.groupby('depth').agg({\n",
    "            'max_tile': ['mean', 'std'],\n",
    "            'final_score': 'mean',\n",
    "            'time_seconds': 'mean',\n",
    "            'moves': 'mean'\n",
    "        })\n",
    "        \n",
    "        ax = axes[0, 0]\n",
    "        depths = depth_stats.index\n",
    "        ax.errorbar(depths, depth_stats['max_tile']['mean'], \n",
    "                   yerr=depth_stats['max_tile']['std'], \n",
    "                   marker='o', capsize=5, linewidth=2)\n",
    "        ax.set_xlabel('Profundidad')\n",
    "        ax.set_ylabel('Max Tile Promedio')\n",
    "        ax.set_title('Impacto de la Profundidad en Max Tile')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Tiempo vs Depth\n",
    "        ax = axes[0, 1]\n",
    "        ax.plot(depths, depth_stats['time_seconds']['mean'], \n",
    "               marker='s', linewidth=2, color='orange')\n",
    "        ax.set_xlabel('Profundidad')\n",
    "        ax.set_ylabel('Tiempo Promedio (segundos)')\n",
    "        ax.set_title('Tiempo de EjecuciÃ³n vs Profundidad')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Score vs Depth\n",
    "        ax = axes[1, 0]\n",
    "        ax.plot(depths, depth_stats['final_score']['mean'], \n",
    "               marker='^', linewidth=2, color='green')\n",
    "        ax.set_xlabel('Profundidad')\n",
    "        ax.set_ylabel('Score Promedio')\n",
    "        ax.set_title('Score vs Profundidad')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Movimientos vs Depth\n",
    "        ax = axes[1, 1]\n",
    "        ax.plot(depths, depth_stats['moves']['mean'], \n",
    "               marker='d', linewidth=2, color='red')\n",
    "        ax.set_xlabel('Profundidad')\n",
    "        ax.set_ylabel('NÃºmero de Movimientos')\n",
    "        ax.set_title('DuraciÃ³n del Juego vs Profundidad')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/plots/depth_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"âœ“ AnÃ¡lisis de profundidad guardado en: results/plots/depth_analysis.png\")\n",
    "        \n",
    "        # Tabla de comparaciÃ³n\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"COMPARACIÃ“N POR PROFUNDIDAD\")\n",
    "        print(\"=\"*60)\n",
    "        display(depth_stats.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315cea92",
   "metadata": {},
   "source": [
    "## 6. AnÃ¡lisis de HeurÃ­sticas\n",
    "\n",
    "ComparaciÃ³n de diferentes configuraciones de heurÃ­sticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaad81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_all is not None and 'heuristic_config' in df_all.columns:\n",
    "    df_heur = df_all[df_all['heuristic_config'].notna()].copy()\n",
    "    \n",
    "    if len(df_heur) > 0:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # ComparaciÃ³n de configuraciones\n",
    "        heur_stats = df_heur.groupby('heuristic_config').agg({\n",
    "            'max_tile': 'mean',\n",
    "            'final_score': 'mean',\n",
    "            'time_seconds': 'mean'\n",
    "        }).sort_values('max_tile', ascending=False)\n",
    "        \n",
    "        # GrÃ¡fico 1: Max Tile\n",
    "        ax = axes[0]\n",
    "        heur_stats['max_tile'].plot(kind='barh', ax=ax, color='skyblue')\n",
    "        ax.set_xlabel('Max Tile Promedio')\n",
    "        ax.set_title('ComparaciÃ³n de Configuraciones HeurÃ­sticas')\n",
    "        ax.grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        # GrÃ¡fico 2: Tiempo vs Performance\n",
    "        ax = axes[1]\n",
    "        ax.scatter(heur_stats['time_seconds'], heur_stats['max_tile'], \n",
    "                  s=200, alpha=0.6, c=range(len(heur_stats)), cmap='viridis')\n",
    "        \n",
    "        for idx, config in enumerate(heur_stats.index):\n",
    "            ax.annotate(config, \n",
    "                       (heur_stats.loc[config, 'time_seconds'], \n",
    "                        heur_stats.loc[config, 'max_tile']),\n",
    "                       xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "        \n",
    "        ax.set_xlabel('Tiempo Promedio (segundos)')\n",
    "        ax.set_ylabel('Max Tile Promedio')\n",
    "        ax.set_title('Trade-off: Tiempo vs Performance')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/plots/heuristic_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"âœ“ AnÃ¡lisis de heurÃ­sticas guardado en: results/plots/heuristic_comparison.png\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"RANKING DE HEURÃSTICAS\")\n",
    "        print(\"=\"*60)\n",
    "        display(heur_stats.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089eaf92",
   "metadata": {},
   "source": [
    "## 7. Alpha-Beta Pruning Analysis\n",
    "\n",
    "AnÃ¡lisis del impacto de Alpha-Beta Pruning en Minimax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c5bd7b",
   "metadata": {},
   "source": [
    "## 7. Alpha-Beta Pruning Analysis\n",
    "\n",
    "AnÃ¡lisis del impacto de Alpha-Beta Pruning en Minimax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1aeb8f",
   "metadata": {},
   "source": [
    "## 8. Minimax vs Expectimax\n",
    "\n",
    "ComparaciÃ³n directa entre los dos algoritmos principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956c387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_all is not None:\n",
    "    # Identificar agentes Minimax y Expectimax\n",
    "    df_minimax = df_all[df_all['agent_name'].str.contains('Minimax', case=False, na=False)]\n",
    "    df_expectimax = df_all[df_all['agent_name'].str.contains('Expectimax', case=False, na=False)]\n",
    "    \n",
    "    if len(df_minimax) > 0 and len(df_expectimax) > 0:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # 1. DistribuciÃ³n de Max Tiles\n",
    "        ax = axes[0, 0]\n",
    "        ax.hist([df_minimax['max_tile'], df_expectimax['max_tile']], \n",
    "               label=['Minimax', 'Expectimax'], bins=20, alpha=0.6)\n",
    "        ax.set_xlabel('Max Tile')\n",
    "        ax.set_ylabel('Frecuencia')\n",
    "        ax.set_title('DistribuciÃ³n de Max Tiles')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Box plot de Max Tile\n",
    "        ax = axes[0, 1]\n",
    "        data_to_plot = [df_minimax['max_tile'], df_expectimax['max_tile']]\n",
    "        ax.boxplot(data_to_plot, labels=['Minimax', 'Expectimax'])\n",
    "        ax.set_ylabel('Max Tile')\n",
    "        ax.set_title('ComparaciÃ³n de Max Tile (Box Plot)')\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # 3. Tiempo promedio\n",
    "        ax = axes[1, 0]\n",
    "        time_comparison = [df_minimax['time_seconds'].mean(), \n",
    "                          df_expectimax['time_seconds'].mean()]\n",
    "        ax.bar(['Minimax', 'Expectimax'], time_comparison, \n",
    "              color=['coral', 'lightblue'], alpha=0.7)\n",
    "        ax.set_ylabel('Tiempo Promedio (segundos)')\n",
    "        ax.set_title('Tiempo de EjecuciÃ³n')\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # 4. ComparaciÃ³n de mÃ©tricas\n",
    "        ax = axes[1, 1]\n",
    "        metrics_comp = pd.DataFrame({\n",
    "            'Minimax': [\n",
    "                df_minimax['max_tile'].mean(),\n",
    "                df_minimax['final_score'].mean() / 1000,  # Escalar para visualizaciÃ³n\n",
    "                df_minimax['moves'].mean() / 10\n",
    "            ],\n",
    "            'Expectimax': [\n",
    "                df_expectimax['max_tile'].mean(),\n",
    "                df_expectimax['final_score'].mean() / 1000,\n",
    "                df_expectimax['moves'].mean() / 10\n",
    "            ]\n",
    "        }, index=['Max Tile', 'Score (Ã·1000)', 'Moves (Ã·10)'])\n",
    "        \n",
    "        metrics_comp.plot(kind='bar', ax=ax, alpha=0.7)\n",
    "        ax.set_title('ComparaciÃ³n de MÃ©tricas Normalizadas')\n",
    "        ax.set_ylabel('Valor')\n",
    "        ax.legend()\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/plots/minimax_vs_expectimax.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"âœ“ ComparaciÃ³n guardada en: results/plots/minimax_vs_expectimax.png\")\n",
    "        \n",
    "        # Tabla comparativa\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"MINIMAX vs EXPECTIMAX - RESUMEN\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        comparison = pd.DataFrame({\n",
    "            'Minimax': [\n",
    "                df_minimax['max_tile'].mean(),\n",
    "                df_minimax['max_tile'].std(),\n",
    "                df_minimax['final_score'].mean(),\n",
    "                df_minimax['moves'].mean(),\n",
    "                df_minimax['time_seconds'].mean(),\n",
    "                len(df_minimax)\n",
    "            ],\n",
    "            'Expectimax': [\n",
    "                df_expectimax['max_tile'].mean(),\n",
    "                df_expectimax['max_tile'].std(),\n",
    "                df_expectimax['final_score'].mean(),\n",
    "                df_expectimax['moves'].mean(),\n",
    "                df_expectimax['time_seconds'].mean(),\n",
    "                len(df_expectimax)\n",
    "            ]\n",
    "        }, index=['Max Tile (promedio)', 'Max Tile (std)', 'Score Final', \n",
    "                  'Movimientos', 'Tiempo (s)', 'Num Partidas'])\n",
    "        \n",
    "        display(comparison.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6b3dac",
   "metadata": {},
   "source": [
    "## 9. Mejor Agente y Recomendaciones\n",
    "\n",
    "IdentificaciÃ³n del mejor agente y conclusiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbc1efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_all is not None:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" \"*20 + \"ðŸ† MEJOR AGENTE ðŸ†\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Rankear por max_tile promedio\n",
    "    rankings = df_all.groupby('agent_name').agg({\n",
    "        'max_tile': ['mean', 'std', 'max'],\n",
    "        'final_score': 'mean',\n",
    "        'moves': 'mean',\n",
    "        'time_seconds': 'mean',\n",
    "        'game_id': 'count'\n",
    "    }).round(2)\n",
    "    \n",
    "    rankings.columns = ['_'.join(col).strip() for col in rankings.columns.values]\n",
    "    rankings = rankings.sort_values('max_tile_mean', ascending=False)\n",
    "    \n",
    "    # Top 5\n",
    "    print(\"TOP 5 AGENTES (por Max Tile promedio):\\n\")\n",
    "    top5 = rankings.head(5)\n",
    "    for idx, (agent, row) in enumerate(top5.iterrows(), 1):\n",
    "        print(f\"{idx}. {agent}\")\n",
    "        print(f\"   Max Tile: {row['max_tile_mean']:.1f} (Â±{row['max_tile_std']:.1f})\")\n",
    "        print(f\"   Mejor: {row['max_tile_max']:.0f}\")\n",
    "        print(f\"   Score: {row['final_score_mean']:.0f}\")\n",
    "        print(f\"   Tiempo: {row['time_seconds_mean']:.2f}s\")\n",
    "        print()\n",
    "    \n",
    "    # Identificar el mejor balance\n",
    "    best_agent = rankings.index[0]\n",
    "    print(\"=\"*70)\n",
    "    print(f\"âœ¨ RECOMENDACIÃ“N: {best_agent}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    best_stats = df_all[df_all['agent_name'] == best_agent]\n",
    "    print(f\"\\nEstadÃ­sticas detalladas:\")\n",
    "    print(f\"  - Partidas jugadas: {len(best_stats)}\")\n",
    "    print(f\"  - Max Tile promedio: {best_stats['max_tile'].mean():.1f}\")\n",
    "    print(f\"  - Probabilidad de 1024+: {(best_stats['max_tile'] >= 1024).sum() / len(best_stats) * 100:.1f}%\")\n",
    "    print(f\"  - Probabilidad de 2048: {(best_stats['max_tile'] >= 2048).sum() / len(best_stats) * 100:.1f}%\")\n",
    "    print(f\"  - Score promedio: {best_stats['final_score'].mean():.0f}\")\n",
    "    print(f\"  - Tiempo promedio: {best_stats['time_seconds'].mean():.2f}s por partida\")\n",
    "    \n",
    "    # Guardar configuraciÃ³n del mejor agente\n",
    "    best_config = {\n",
    "        'agent_name': best_agent,\n",
    "        'stats': best_stats.describe().to_dict(),\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    with open('models/best_agent_config.json', 'w') as f:\n",
    "        json.dump(best_config, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"\\nâœ“ ConfiguraciÃ³n guardada en: models/best_agent_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac322054",
   "metadata": {},
   "source": [
    "## 10. Resumen Ejecutivo para el Informe\n",
    "\n",
    "Genera un resumen con los hallazgos principales para incluir en el informe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b44a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_all is not None:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" \"*15 + \"ðŸ“Š RESUMEN EJECUTIVO ðŸ“Š\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Hallazgos principales\n",
    "    total_games = len(df_all)\n",
    "    total_agents = df_all['agent_name'].nunique()\n",
    "    total_time = df_all['time_seconds'].sum() / 3600  # en horas\n",
    "    \n",
    "    print(f\"EXPERIMENTOS REALIZADOS:\")\n",
    "    print(f\"  â€¢ Total de partidas: {total_games}\")\n",
    "    print(f\"  â€¢ Agentes evaluados: {total_agents}\")\n",
    "    print(f\"  â€¢ Tiempo total de computaciÃ³n: {total_time:.2f} horas\")\n",
    "    \n",
    "    print(f\"\\nRESULTADOS GENERALES:\")\n",
    "    print(f\"  â€¢ Max Tile promedio (todos los agentes): {df_all['max_tile'].mean():.1f}\")\n",
    "    print(f\"  â€¢ Mejor max tile alcanzado: {df_all['max_tile'].max():.0f}\")\n",
    "    print(f\"  â€¢ Partidas que alcanzaron 2048: {(df_all['max_tile'] >= 2048).sum()} ({(df_all['max_tile'] >= 2048).sum()/total_games*100:.1f}%)\")\n",
    "    \n",
    "    # ComparaciÃ³n de algoritmos\n",
    "    if 'Minimax' in df_all['agent_name'].str.cat() and 'Expectimax' in df_all['agent_name'].str.cat():\n",
    "        minimax_avg = df_all[df_all['agent_name'].str.contains('Minimax', na=False)]['max_tile'].mean()\n",
    "        expectimax_avg = df_all[df_all['agent_name'].str.contains('Expectimax', na=False)]['max_tile'].mean()\n",
    "        \n",
    "        print(f\"\\nCOMPARACIÃ“N MINIMAX vs EXPECTIMAX:\")\n",
    "        print(f\"  â€¢ Minimax - Max Tile promedio: {minimax_avg:.1f}\")\n",
    "        print(f\"  â€¢ Expectimax - Max Tile promedio: {expectimax_avg:.1f}\")\n",
    "        \n",
    "        if expectimax_avg > minimax_avg:\n",
    "            diff = ((expectimax_avg - minimax_avg) / minimax_avg) * 100\n",
    "            print(f\"  â€¢ Expectimax supera a Minimax en {diff:.1f}%\")\n",
    "            print(f\"  âœ“ ConclusiÃ³n: Expectimax es mÃ¡s adecuado para juegos estocÃ¡sticos\")\n",
    "        else:\n",
    "            diff = ((minimax_avg - expectimax_avg) / expectimax_avg) * 100\n",
    "            print(f\"  â€¢ Minimax supera a Expectimax en {diff:.1f}%\")\n",
    "    \n",
    "    # Impacto de profundidad\n",
    "    if 'depth' in df_all.columns:\n",
    "        depth_impact = df_all.groupby('depth')['max_tile'].mean()\n",
    "        if len(depth_impact) > 1:\n",
    "            print(f\"\\nIMPACTO DE LA PROFUNDIDAD:\")\n",
    "            for depth, avg_tile in depth_impact.items():\n",
    "                print(f\"  â€¢ Profundidad {depth}: {avg_tile:.1f}\")\n",
    "    \n",
    "    # Mejores configuraciones\n",
    "    print(f\"\\nCONFIGURACIONES Ã“PTIMAS:\")\n",
    "    top3 = df_all.groupby('agent_name')['max_tile'].mean().nlargest(3)\n",
    "    for i, (agent, score) in enumerate(top3.items(), 1):\n",
    "        print(f\"  {i}. {agent}: {score:.1f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âœ“ Este resumen puede ser incluido directamente en el informe\")\n",
    "    print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
